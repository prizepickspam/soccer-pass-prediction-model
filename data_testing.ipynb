{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e0711c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "pd.set_option('display.max_columns', 1000)\n",
    "pd.set_option('display.max_rows', 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc7a08d",
   "metadata": {},
   "source": [
    "# statsperform API + bq backloading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19de6027",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _access_statsperform_api(feed_name: str,\n",
    "                             tourney_cal_id: str = None,\n",
    "                             match_id: str = None\n",
    "                             ):\n",
    "\n",
    "    proxy_url = \"http://127.0.0.1:3128\"\n",
    "    statsperform_base_url = 'https://api.performfeeds.com/soccerdata'\n",
    "    auth_key = str(os.environ['STATSPERFORM_API_KEY'])\n",
    "\n",
    "    master_dict = {\n",
    "        '_rt':'b',\n",
    "        '_fmt':'json'\n",
    "    }\n",
    "\n",
    "    if feed_name == 'match':\n",
    "        assert tourney_cal_id is not None, \"To access match feed data, a tournament calendar ID must be passed in.\"\n",
    "        master_dict['tmcl'] = tourney_cal_id\n",
    "        master_dict['_pgSz'] = 1000\n",
    "    if feed_name == 'matchstats':\n",
    "        assert match_id is not None, \"To access match stats feed, a match ID must be passed in.\"\n",
    "        master_dict['fx'] = match_id\n",
    "        master_dict['detailed'] = 'yes'\n",
    "        master_dict['people'] = 'yes'\n",
    "\n",
    "    query_string = '&'.join([f'{k}={v}' for k, v in master_dict.items()])\n",
    "\n",
    "    q_command = f\"\"\" curl -x \"{proxy_url}\" '{statsperform_base_url}/{feed_name}/{auth_key}/authorized?&{query_string}' \"\"\" if feed_name == 'tournamentcalendar' else \\\n",
    "        f\"\"\" curl -x \"{proxy_url}\" '{statsperform_base_url}/{feed_name}/{auth_key}?&{query_string}' \"\"\"\n",
    "\n",
    "    # print(q_command)\n",
    "\n",
    "    process = subprocess.run(\n",
    "                q_command,\n",
    "                shell=True,\n",
    "                capture_output=True,\n",
    "                check=False # Set to True if you want a CalledProcessError for non-zero exit codes\n",
    "            )\n",
    "\n",
    "    stdout = process.stdout\n",
    "    json_output = json.loads(stdout)\n",
    "    return json_output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba30d6b",
   "metadata": {},
   "source": [
    "## tournaments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2049e914",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_statsperform_tourneys(to_bq=False):\n",
    "    # Get all available tournament calendar IDs with OT2 feed\n",
    "    feed = 'tournamentcalendar'\n",
    "    comps = _access_statsperform_api(feed)\n",
    "    competitions = pd.DataFrame(comps['competition'])\n",
    "    competitions = competitions.explode('tournamentCalendar')\n",
    "\n",
    "    extended_tourneys = pd.json_normalize(competitions['tournamentCalendar'])\n",
    "    extended_tourneys.columns = ['tourneyCalId', 'includesVenues', 'tcOcId', 'tcName', 'startDate', 'endDate', 'active', 'lastUpdated', 'includesStandings']\n",
    "\n",
    "    final_df = pd.concat([competitions.drop(columns=['tournamentCalendar']).reset_index(drop=True),\n",
    "                      extended_tourneys.reset_index(drop=True)], axis=1)\n",
    "                                \n",
    "    if to_bq:\n",
    "        try:\n",
    "            final_df.to_gbq('soccer_simulations.tourneycal_data',\n",
    "                    'prizepicksanalytics',\n",
    "                    if_exists='fail')\n",
    "        except Exception as e:\n",
    "            print(\"Table already exists on BQ!\")\n",
    "\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "296971d8",
   "metadata": {},
   "source": [
    "## matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254af8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all matches with MA1 feed\n",
    "def _get_all_matches_in_tourneycal(tourney_cal_id: str):\n",
    "\n",
    "    all_matches = _access_statsperform_api(feed_name='match',\n",
    "                         tourney_cal_id=tourney_cal_id)\n",
    "\n",
    "    return pd.DataFrame([x['matchInfo'] for x in all_matches['match']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0cf3f14",
   "metadata": {},
   "source": [
    "## process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4caba185",
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = _get_all_matches_in_tourneycal(tourney_cal_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80fb8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm_notebook\n",
    "import config\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cafe3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "teams, players = backload_season_data(tourney_cal_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6646ebce",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# getting access to player data using MA2 feed\n",
    "def backload_season_data(tourney_cal_id, \n",
    "                         game_limit=None,\n",
    "                         project_name: str = 'prizepicksanalytics',\n",
    "                        table_name: str = f'soccer_simulations.schema_match_data'):\n",
    "    \n",
    "    matches = _get_all_matches_in_tourneycal(tourney_cal_id)\n",
    "\n",
    "    processed_match_ids = list(get_processed_match_ids().match_id)\n",
    "    list_of_matches = [x for x in matches.id.unique() if x not in processed_match_ids]\n",
    "\n",
    "    if game_limit:\n",
    "        list_of_matches = list_of_matches[:game_limit]\n",
    "\n",
    "    all_teams = []\n",
    "    all_players = []\n",
    "\n",
    "    for i, id in enumerate(list_of_matches):\n",
    "\n",
    "        if id in processed_match_ids:\n",
    "            continue\n",
    "\n",
    "        print(f\"Now processing match #{i}: {id}\")\n",
    "        team, player = process_game_data(id)\n",
    "\n",
    "        all_players.append(player)\n",
    "        all_teams.append(team)\n",
    "        \n",
    "\n",
    "    if all_teams and all_players:\n",
    "        team_data_to_bq = pd.concat(all_teams, axis=0, ignore_index=True)\n",
    "        team_data_to_bq.to_gbq(table_name.replace('schema', 'team'),\n",
    "                project_name,\n",
    "                if_exists='append')\n",
    "        \n",
    "        player_data_to_bq = pd.concat(all_players, axis=0, ignore_index=True)\n",
    "        player_data_to_bq.to_gbq(table_name.replace('schema', 'player'),\n",
    "                project_name,\n",
    "                if_exists='append')\n",
    "        \n",
    "        print(f\"Team and Player Data Uploaded for the following Game Ids: {team_data_to_bq.match_id.unique()}\")\n",
    "        return team, player\n",
    "    else:\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03037793",
   "metadata": {},
   "outputs": [],
   "source": [
    "# players.to_csv('./test_players.csv', index=False)\n",
    "# teams.to_csv('./test_teams.csv', index=False)\n",
    "# players = pd.read_csv('./test_players.csv', index_col=0)\n",
    "# teams = pd.read_csv('./test_teams.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a95733",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery as bqc\n",
    "\n",
    "\n",
    "# DataFrame should be of only one match\n",
    "def check_bq_duplicates(dataframe: pd.DataFrame,\n",
    "                        schema: str,\n",
    "                        project_name: str = 'prizepicksanalytics',\n",
    "                        table_name: str = f'soccer_simulations.schema_match_data'):\n",
    "    \n",
    "    assert dataframe.shape[0] != 0, \"Empty dataframes not accepted\"\n",
    "    assert schema in ['team', 'player'], \"Only team and player data accepted\"\n",
    "    table_name = table_name.replace('schema', schema)\n",
    "\n",
    "    match_ids = list(dataframe.match_id.unique())\n",
    "\n",
    "    column_key = 'team_id' if schema == 'team' else 'playerId'\n",
    "\n",
    "    query = f\"\"\"\n",
    "        select match_id, {column_key}\n",
    "        from {project_name}.{table_name}\n",
    "        where match_id in ({\", \".join([\"'\" + x + \"'\" for x in match_ids])}) \n",
    "    \"\"\"\n",
    "\n",
    "    rows_on_bq = execute_bq_query(query)\n",
    "\n",
    "    if rows_on_bq.shape[0] == dataframe.shape[0]:\n",
    "        print(f\"Data already loaded onto BQ for Match Id: {match_ids} Schema: {schema}\")\n",
    "        return\n",
    "    else:\n",
    "        dataframe = dataframe.merge(rows_on_bq,\n",
    "                                    on=['match_id', column_key],\n",
    "                                    how='left',\n",
    "                                    indicator=True)\n",
    "        \n",
    "        dataframe = dataframe[dataframe['_merge'] == 'left_only'].drop(columns=['_merge'])\n",
    "        \n",
    "\n",
    "    return dataframe\n",
    "\n",
    "def get_processed_match_ids():\n",
    "    query = \"\"\"\n",
    "        select distinct match_id\n",
    "        from prizepicksanalytics.soccer_simulations.team_match_data\n",
    "    \"\"\"\n",
    "\n",
    "    return execute_bq_query(query)\n",
    "\n",
    "\n",
    "def execute_bq_query(query: str) -> pd.DataFrame:\n",
    "    bigquery_client = bqc.Client(project='prizepicksanalytics')\n",
    "    query_results = bigquery_client.query(query)\n",
    "    data = query_results.to_dataframe()\n",
    "    bigquery_client.close()\n",
    "\n",
    "    return data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47cfd2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_game_data(match_id):\n",
    "    \n",
    "    match_data = _access_statsperform_api(feed_name='matchstats',\n",
    "                         match_id=match_id)\n",
    "    \n",
    "    # TODO: \n",
    "    team_data = _aggregate_team_data(match_data)\n",
    "\n",
    "    player_data = _aggregate_player_data(match_data)\n",
    "    \n",
    "    return team_data, player_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a75fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# method to aggregate team data\n",
    "\n",
    "def _aggregate_team_data(match_stats):\n",
    "\n",
    "    # collect tournament calendar, competition and team information\n",
    "    tourney_cal_id, tourney_cal_season = match_stats['matchInfo']['tournamentCalendar']['id'], \\\n",
    "        match_stats['matchInfo']['tournamentCalendar']['name']\n",
    "    competition_id, competition_name = match_stats['matchInfo']['competition']['id'], \\\n",
    "        match_stats['matchInfo']['competition']['name']\n",
    "    \n",
    "    competitors = match_stats['matchInfo']['contestant']\n",
    "    \n",
    "    # turn match data into dataframe\n",
    "    match_data = pd.DataFrame(match_stats['liveData']['lineUp'])\n",
    "\n",
    "    match_list = []\n",
    "\n",
    "    for _, team in match_data.iterrows():\n",
    "        # turn statistics into numerics and get team object from competitor\n",
    "        team_stats = pd.DataFrame(team.stat)\n",
    "        team_stats['value'] = pd.to_numeric(team_stats.value)\n",
    "        competitor = competitors[0] if competitors[0]['id'] == team.contestantId else competitors[1]\n",
    "\n",
    "        # transpose statistics to make ts dataframe (team statistics)\n",
    "        ts = team_stats[['type', 'value']].set_index('type').T\n",
    "\n",
    "        stat_cols = ts.columns\n",
    "        missing_cols = set(config.all_team_match_stats).difference(stat_cols)\n",
    "\n",
    "        if missing_cols:\n",
    "            missing_df = pd.DataFrame(0, index=ts.index, columns=list(missing_cols), dtype=float)\n",
    "            ts = pd.concat([ts, missing_df], axis=1)\n",
    "\n",
    "        # create dataframe for cs (config statistics)\n",
    "        cs = pd.DataFrame({\n",
    "            'competition_id': [competition_id],\n",
    "            'competition_name': [competition_name],\n",
    "            'tourney_cal_id': [tourney_cal_id],\n",
    "            'tourney_cal_name': [tourney_cal_season],\n",
    "            'match_id' : [match_stats['matchInfo']['id']],\n",
    "            'match_date': match_stats['matchInfo']['date'],\n",
    "            'team_id' : [str(competitor['id'])],\n",
    "            'team_name': [str(competitor['shortName'])],\n",
    "            'home' : True if competitor['position'] == 'home' else False,\n",
    "        })\n",
    "\n",
    "        team_row = pd.concat([cs.reset_index(drop=True), ts[config.all_team_match_stats].reset_index(drop=True)], axis=1)\n",
    "        team_row['formationUsed'] = str(team.formationUsed)\n",
    "\n",
    "        match_list.append(team_row)\n",
    "\n",
    "    # return dataframe of len == 2 with rows representing both teams, sharing the same game_id\n",
    "    return pd.concat(match_list).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8027c50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# method to aggregate player data\n",
    "\n",
    "def _aggregate_player_data(match_request):\n",
    "    match_data = pd.DataFrame(match_request['liveData']['lineUp'])\n",
    "\n",
    "    subs = pd.DataFrame(match_request['liveData']['substitute']).set_index('playerOnId').to_dict('index')\n",
    "\n",
    "    list_of_dfs = []\n",
    "\n",
    "    for _, team in match_data.iterrows():\n",
    "        players = pd.DataFrame(team['player'])\n",
    "\n",
    "        # replace substitution position with boolean column\n",
    "        players['isSub'] = players.position.apply(lambda x: True if x == 'Substitute' else False)\n",
    "        cols_to_keep = ['playerId', 'matchName', 'position', 'positionSide', 'isSub']\n",
    "\n",
    "        # turn statistics json into pandas dataframe + make all numbers into floats\n",
    "        stats = players.stat.apply(lambda lisa: {x['type']:float(x['value']) for x in lisa})\n",
    "        players = pd.concat([players[cols_to_keep].reset_index(drop=True), pd.json_normalize(stats).reset_index(drop=True)], axis=1)\n",
    "\n",
    "        # remove all players from dataframe who didn't play\n",
    "        players = players[~players['minsPlayed'].isna()]\n",
    "\n",
    "        # checks all subs in players dataframe, replace values with subbed out player info\n",
    "        subbed_players = players[players['isSub'] == True]\n",
    "\n",
    "        # replace substitution position info with player who subbed out for substitute\n",
    "        for i, row in subbed_players.iterrows():\n",
    "            sub_info = subs[row.playerId]\n",
    "            subbed_out_player = players[players['playerId'] == sub_info['playerOffId']].iloc[0]\n",
    "\n",
    "            players.at[i, 'position'] =  subbed_out_player.position\n",
    "            players.at[i, 'positionSide'] =  subbed_out_player.positionSide\n",
    "            players.at[i, 'formationPlace'] =  subbed_out_player.formationPlace\n",
    "\n",
    "        # add config columns\n",
    "        players.insert(0, 'match_id', match_request['matchInfo']['id'])\n",
    "        players.insert(1, 'team_id', team.contestantId)\n",
    "        config_cols = ['match_id', 'team_id'] + cols_to_keep\n",
    "\n",
    "        # add all columns not found in player data to keep StatsPerform detailed player statistics schema \n",
    "        # (schema can be found in config.py)\n",
    "        stat_cols = players.drop(config_cols, axis=1).columns\n",
    "        missing_cols = set(config.all_player_match_stats).difference(stat_cols)\n",
    "\n",
    "        if missing_cols:\n",
    "            missing_df = pd.DataFrame(0, index=players.index, columns=list(missing_cols), dtype=float)\n",
    "            players = pd.concat([players, missing_df], axis=1)\n",
    "\n",
    "        list_of_dfs.append(players[config_cols + config.all_player_match_stats])\n",
    "\n",
    "    # return dataframe of all players with their statistics\n",
    "    return pd.concat(list_of_dfs, axis=0, ignore_index=True).fillna(0)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1458943",
   "metadata": {},
   "source": [
    "# feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dadd050",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e444f8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import data\n",
    "importlib.reload(data)\n",
    "from data import DataLoader\n",
    "\n",
    "prem2425 = '9n12waklv005j8r32sfjj2eqc'\n",
    "\n",
    "prem_loader = DataLoader(prem2425)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7f4173",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tourneys = get_statsperform_tourneys()\n",
    "ars_lfc_match = prem_loader.matches.iloc[290]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bedb491e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_historic_team_data(match):\n",
    "\n",
    "        home_query = f\"\"\"\n",
    "                select *\n",
    "                from prizepicksanalytics.soccer_simulations.team_match_data\n",
    "                where team_id = '{match.home_id}'\n",
    "                and date(REPLACE(match_date, 'Z', '')) < date('{match.localDate}')\n",
    "                \"\"\"\n",
    "        \n",
    "        away_query = f\"\"\"\n",
    "                select *\n",
    "                from prizepicksanalytics.soccer_simulations.team_match_data\n",
    "                where team_id = '{match.away_id}'\n",
    "                and date(REPLACE(match_date, 'Z', '')) < date('{match.localDate}')\n",
    "                \"\"\"\n",
    "\n",
    "\n",
    "        return prem_loader.execute_bq_query(home_query),   prem_loader.execute_bq_query(away_query)\n",
    "\n",
    "def get_squads(match):\n",
    "\n",
    "        home_query = f\"\"\"\n",
    "                select *\n",
    "                from prizepicksanalytics.soccer_simulations.squad_data\n",
    "                where contestantId = '{match.home_id}'\n",
    "                \"\"\"\n",
    "        \n",
    "        away_query = f\"\"\"\n",
    "                select *\n",
    "                from prizepicksanalytics.soccer_simulations.squad_data\n",
    "                where contestantId = '{match.away_id}'\n",
    "                \"\"\"\n",
    "\n",
    "\n",
    "        return prem_loader.execute_bq_query(home_query),   prem_loader.execute_bq_query(away_query)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "ars_data, liv_data = get_historic_team_data(ars_lfc_match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5af1799",
   "metadata": {},
   "outputs": [],
   "source": [
    "liv_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c2ab63",
   "metadata": {},
   "outputs": [],
   "source": [
    "squads.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7f9005",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_squads(self,\n",
    "                to_bq=False):\n",
    "    squads = prem_loader._access_statsperform_api('squads')\n",
    "\n",
    "    squads = pd.DataFrame(squads['squad'])\n",
    "    squads = squads.explode('person')\n",
    "\n",
    "    exploded_data = pd.json_normalize(squads['person'])\n",
    "\n",
    "    final_squad = pd.concat([squads.drop(columns=['person', 'venueName', 'venueId', 'teamKits']).reset_index(drop=True), exploded_data], axis=1)\n",
    "\n",
    "    if to_bq:\n",
    "        try:\n",
    "            final_squad.to_gbq('soccer_simulations.tourneycal_data',\n",
    "                            self.bq_project,\n",
    "                            if_exists='fail')\n",
    "            \n",
    "        except Exception as e:\n",
    "            print('Table already exists!')\n",
    "    \n",
    "    return final_squad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7821a189",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_squad[final_squad['contestantShortName'] == 'Arsenal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403d327c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

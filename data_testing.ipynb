{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e0711c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "pd.set_option('display.max_columns', 1000)\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc7a08d",
   "metadata": {},
   "source": [
    "# statsperform API + bq backloading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa939eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import data\n",
    "importlib.reload(data)\n",
    "from data import DataLoader\n",
    "\n",
    "prem2425 = '9n12waklv005j8r32sfjj2eqc'\n",
    "\n",
    "prem_loader = DataLoader(prem2425)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1458943",
   "metadata": {},
   "source": [
    "# feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dadd050",
   "metadata": {},
   "source": [
    "## data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bedb491e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_team_data():\n",
    "        query = f\"\"\"\n",
    "                select *\n",
    "                from prizepicksanalytics.soccer_simulations.team_match_data\n",
    "                \"\"\"\n",
    "        \n",
    "        return prem_loader.execute_bq_query(query)\n",
    "\n",
    "def get_all_player_data():\n",
    "        query = f\"\"\"\n",
    "                select *\n",
    "                from prizepicksanalytics.soccer_simulations.player_match_data\n",
    "                \"\"\"\n",
    "        \n",
    "        return prem_loader.execute_bq_query(query)\n",
    "\n",
    "def get_historic_team_data(match):\n",
    "\n",
    "        home_query = f\"\"\"\n",
    "                select *\n",
    "                from prizepicksanalytics.soccer_simulations.team_match_data\n",
    "                where team_id = '{match.home_id}'\n",
    "                and date(REPLACE(match_date, 'Z', '')) < date('{match.localDate}')\n",
    "                \"\"\"\n",
    "        \n",
    "        away_query = f\"\"\"\n",
    "                select *\n",
    "                from prizepicksanalytics.soccer_simulations.team_match_data\n",
    "                where team_id = '{match.away_id}'\n",
    "                and date(REPLACE(match_date, 'Z', '')) < date('{match.localDate}')\n",
    "                \"\"\"\n",
    "\n",
    "\n",
    "        return prem_loader.execute_bq_query(home_query),   prem_loader.execute_bq_query(away_query)\n",
    "\n",
    "\n",
    "# def get_historic_player_data(match,\n",
    "#                              list_of_player_ids):\n",
    "        \n",
    "#         player_query = f\"\"\"\n",
    "#                 select *\n",
    "#                 from prizepicksanalytics.soccer_simulations.player_match_data\n",
    "#                 where playerId in ({\", \".join([\"'\" + x + \"'\" for x in list_of_player_ids])})\n",
    "#                 and date(REPLACE(match_date, 'Z', '')) < date('{match.localDate}')\n",
    "#                 \"\"\"\n",
    "\n",
    "\n",
    "#         return prem_loader.execute_bq_query(player_query)\n",
    "\n",
    "        # return player_query\n",
    "\n",
    "def get_squads(match):\n",
    "\n",
    "        home_query = f\"\"\"\n",
    "                select *\n",
    "                from prizepicksanalytics.soccer_simulations.squad_data\n",
    "                where contestantId = '{match.home_id}'\n",
    "                \"\"\"\n",
    "        \n",
    "        away_query = f\"\"\"\n",
    "                select *\n",
    "                from prizepicksanalytics.soccer_simulations.squad_data\n",
    "                where contestantId = '{match.away_id}'\n",
    "                \"\"\"\n",
    "\n",
    "\n",
    "        return prem_loader.execute_bq_query(home_query), prem_loader.execute_bq_query(away_query)\n",
    "\n",
    "\n",
    "def get_calendar():\n",
    "    query = \"\"\"\n",
    "        select * from prizepicksanalytics.soccer_simulations.match_calendar\n",
    "    \"\"\"\n",
    "    return prem_loader.execute_bq_query(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12f93e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# away_query = f\"\"\"\n",
    "#                 select *\n",
    "#                 from prizepicksanalytics.soccer_simulations.squad_data\n",
    "#                 \"\"\"\n",
    "\n",
    "\n",
    "# squad_data = prem_loader.execute_bq_query(away_query)\n",
    "\n",
    "# calendar_data = get_calendar()\n",
    "# calendar_data.to_csv('calendar_data.csv', index=False)\n",
    "\n",
    "\n",
    "# tourneys = get_statsperform_tourneys()\n",
    "# team_data = get_all_team_data()\n",
    "# team_data.to_csv('team_data.csv', index=False)\n",
    "# player_data = get_all_player_data()\n",
    "# player_data.to_csv('player_data.csv', index=False)\n",
    "# ars_lfc_match = prem_loader.matches.iloc[290]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c45489",
   "metadata": {},
   "source": [
    "## agg methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4149850c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_team_stats_vector(team_data,\n",
    "                           opposite_team_data,\n",
    "                           position):\n",
    "    \n",
    "    home = True if position == 'home' else False\n",
    "\n",
    "    if team_data.shape[0] == 0:\n",
    "        avg_possession = np.nan\n",
    "        weighted_possession = np.nan\n",
    "    else:\n",
    "        avg_possession = team_data.possessionPercentage.mean()\n",
    "        weighted_possession = (team_data.possessionPercentage * team_data.poss_weight).sum() / team_data.poss_weight.sum()\n",
    "\n",
    "\n",
    "    \n",
    "    return {\n",
    "        't_avg_possession': avg_possession,\n",
    "        \"t_posw_possession\": weighted_possession\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "def _get_player_stats(player_performances,\n",
    "                      position):\n",
    "    home = True if position == 'home' else False\n",
    "\n",
    "    if player_performances.shape[0] == 0:\n",
    "        avg_passAtt = np.nan\n",
    "        std_passAtt = np.nan\n",
    "        avg_minsPlayed = np.nan\n",
    "        # last5_mins = np.nan\n",
    "        weighted_passAtt = np.nan\n",
    "\n",
    "    else:\n",
    "        avg_passAtt = player_performances.totalPass.mean()\n",
    "        std_passAtt = player_performances.totalPass.std()\n",
    "        avg_minsPlayed = player_performances.minsPlayed.mean()\n",
    "        # last5_mins = player_performances\n",
    "        weighted_passAtt = (player_performances['totalPass'] * player_performances['poss_weight'].astype(float)).sum() / player_performances['poss_weight'].astype(float).sum()\n",
    "    \n",
    "    \n",
    "    return {\n",
    "        'p_avg_passes': avg_passAtt,\n",
    "        'p_std_passes': std_passAtt,\n",
    "        'p_avg_minsPlayed': avg_minsPlayed,\n",
    "        'p_weighted_passes': weighted_passAtt\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4715c46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# team_mappings = {\n",
    "#   \"b9si1jn1lfxfund69e9ogcu2n\": \"Wolves\",\n",
    "#   \"7yx5dqhhphyvfisohikodajhv\": \"Brentford\",\n",
    "#   \"22doj4sgsocqpxw45h607udje\": \"Tottenham\",\n",
    "#   \"e5p0ehyguld7egzhiedpdnc3w\": \"Brighton\",\n",
    "#   \"d5ydtvt96bv7fq04yqm2w2632\": \"Southampton\",\n",
    "#   \"4dsgumo7d4zupm2ugsvm4zm4d\": \"Arsenal\",\n",
    "#   \"1qtaiy11gswx327s0vkibf70n\": \"Nottm Forest\",\n",
    "#   \"9q0arba2kbnywth8bkxlhgmdr\": \"Chelsea\",\n",
    "#   \"7vn2i2kd35zuetw6b38gw9jsz\": \"Newcastle\",\n",
    "#   \"ehd2iemqmschhj2ec0vayztzz\": \"Everton\",\n",
    "#   \"6eqit8ye8aomdsrrq0hk3v7gh\": \"Man Utd\",\n",
    "#   \"b496gs285it6bheuikox6z9mj\": \"Aston Villa\",\n",
    "#   \"c8h9bw1l82s06h77xxrelzhur\": \"Liverpool\",\n",
    "#   \"1c8m2ko0wxq1asfkuykurdr0y\": \"Crystal Palace\",\n",
    "#   \"8b523ujgl21tbc01me65q0aoh\": \"Ipswich\",\n",
    "#   \"4txjdaqveermfryvbfrr4taf7\": \"West Ham\",\n",
    "#   \"hzqh7z0mdl3v7gwete66syxp\": \"Fulham\",\n",
    "#   \"a3nyxabgsqlnqfkeg41m6tnpp\": \"Man City\",\n",
    "#   \"1pse9ta7a45pi2w2grjim70ge\": \"Bournemouth\",\n",
    "#   \"avxknfz4f6ob0rv9dbnxdzde0\": \"Leicester\"\n",
    "# }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3236050",
   "metadata": {},
   "source": [
    "## get match vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403d327c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def gaussian_weight(historic_possession, predicted_next_possession, bandwidth=10.0):\n",
    "    \"\"\"\n",
    "    Calculates a Gaussian weight based on the similarity of possession percentages.\n",
    "    Bandwidth (sigma) controls how quickly the weight drops off.\n",
    "    \"\"\"\n",
    "    difference = historic_possession - predicted_next_possession\n",
    "    # Larger bandwidth means less sensitive to differences\n",
    "    return np.exp(-(difference**2) / (2 * bandwidth**2))\n",
    "\n",
    "    \n",
    "def get_match_vectors(match,\n",
    "                      all_performances = None,\n",
    "                      all_squads=None,\n",
    "                      all_player_data=None,\n",
    "                      training=True):\n",
    "\n",
    "    final_feat_list = []\n",
    "\n",
    "    team_ids = {'home':match.home_id,\n",
    "                'away':match.away_id}\n",
    "\n",
    "    if all_performances is None:\n",
    "        home_data, away_data = get_historic_team_data(match)\n",
    "    else:\n",
    "        home_data = all_performances[(all_performances['team_id'] == team_ids['home']) &\n",
    "                                     (all_performances['match_date'].apply(lambda x: x.replace('Z', '')) < match.localDate)]\n",
    "        \n",
    "        away_data = all_performances[(all_performances['team_id'] == team_ids['away']) &\n",
    "                                     (all_performances['match_date'].apply(lambda x: x.replace('Z', '')) < match.localDate)]\n",
    "\n",
    "    team_data = {\n",
    "        'home':home_data,\n",
    "        'away':away_data\n",
    "    }\n",
    "\n",
    "    if all_squads is None:\n",
    "        home_squad, away_squad = get_squads(match)\n",
    "    else:\n",
    "        home_squad, away_squad = all_squads[team_ids['home']], all_squads[team_ids['away']]\n",
    "\n",
    "    squad_data = {\n",
    "        'home':home_squad,\n",
    "        'away':away_squad\n",
    "    }\n",
    "\n",
    "    # print(match.description)\n",
    "    for team in ['home', 'away']:\n",
    "        \n",
    "\n",
    "        mask2 = (all_performances['match_id'] == match.id) & (all_performances['team_id'] == team_ids[team])\n",
    "        # USED FOR GAUSSIAN KERNEL\n",
    "        cheat_possession = all_performances[mask2].iloc[0].possessionPercentage\n",
    "\n",
    "        # print(f\"{match.description.split(' vs ')[0 if team == 'home' else 1]} - Possession: {cheat_possession}\")\n",
    "\n",
    "        # GAUSSIAN KERNEL APPLICATION\n",
    "        team_data[team]['poss_weight'] = gaussian_weight(team_data[team].possessionPercentage, \n",
    "                                                         cheat_possession,\n",
    "                                                         team_data[team].possessionPercentage.std())\n",
    "        \n",
    "        # team_data[team]['opponent_id'] = team_data[team]['opponent_id'].apply(lambda x: team_mappings[x])\n",
    "        # print(team_data[team][['opponent_id', 'possessionPercentage', 'poss_weight']].sort_values('poss_weight', ascending=False).reset_index(drop=True))\n",
    "        \n",
    "\n",
    "        opposite_position = 'away' if team == 'home' else 'home'\n",
    "\n",
    "        team_stats_vector = _get_team_stats_vector(team_data[team],\n",
    "                                                      team_data[opposite_position],\n",
    "                                                      team)\n",
    "        \n",
    "        \n",
    "        team_squad = squad_data[team]\n",
    "\n",
    "        if all_player_data is None:\n",
    "            historical_player_data = get_historic_player_data(match, list(team_squad.id.unique()))\n",
    "        else: \n",
    "            historical_player_data = all_player_data[(all_player_data['playerId'].isin(team_squad.id.unique())) &\n",
    "                                                      (all_player_data['match_date'].apply(lambda x: x.replace('Z', '')) < match.localDate)]\n",
    "            \n",
    "        # merge match weights on historical player data\n",
    "        historical_player_data = historical_player_data.merge(team_data[team][['match_id', 'team_id', 'poss_weight']],\n",
    "                                     how='left',\n",
    "                                     on=['match_id', 'team_id'])\n",
    "        \n",
    "            \n",
    "        # team_squad = team_squad[team_squad['id'].isin(historical_player_data.playerId.unique())]\n",
    "        team_squad = all_player_data[(all_player_data['team_id'] == team_ids[team]) & (all_player_data['match_id'] == match.id)]\n",
    "\n",
    "        for i, player in team_squad.iterrows():\n",
    "\n",
    "            final_dict = {\n",
    "                'player_id':player.playerId,\n",
    "                'player_name':player.matchName,\n",
    "                'player_position':player.position,\n",
    "                'team_id':team_ids[team],\n",
    "                'match_id':match.id,\n",
    "                'match_date':match.localDate,\n",
    "                'match_week':match.week,\n",
    "                'is_home':True if team == 'home' else False\n",
    "                # 'cheating_possession':\n",
    "            }\n",
    "\n",
    "            # print('player id', player.playerId)\n",
    "\n",
    "            player_performances = historical_player_data[historical_player_data['playerId'] == player.playerId]\n",
    "\n",
    "\n",
    "            player_vector = _get_player_stats(player_performances,\n",
    "                                              team)\n",
    "            \n",
    "            final_dict.update(player_vector)\n",
    "            final_dict.update(team_stats_vector)      \n",
    "\n",
    "            # print(final_dict['p_weighted_passes'])    \n",
    "\n",
    "            if training == True:\n",
    "                try:\n",
    "                    mask = (all_player_data['match_id'] == match.id) & (all_player_data['playerId'] == player.playerId)\n",
    "                    performance = all_player_data[mask].iloc[0]\n",
    "                    final_dict['target'] = performance.totalPass\n",
    "                    \n",
    "                    final_dict['is_sub'] = performance.isSub\n",
    "                    # final_dict['cheat_possession'] = cheat_possession\n",
    "\n",
    "                except IndexError as e:\n",
    "                    continue\n",
    "        \n",
    "            # player_vector['match_id'] = match.id\n",
    "            # player_vector['match_date'] = match.localDate\n",
    "            # player_vector['match_week'] = match.week\n",
    "\n",
    "            final_feat_list.append(final_dict)\n",
    "        \n",
    "    return final_feat_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b81ca8",
   "metadata": {},
   "source": [
    "## feature generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d675fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "calendar = pd.read_csv('match_calendar.csv')\n",
    "\n",
    "team_data = pd.read_csv('team_data.csv')\n",
    "team_data = team_data.sort_values(['match_date'], ascending=True).reset_index(drop=True)\n",
    "\n",
    "player_data = pd.read_csv('player_data.csv')\n",
    "player_data = player_data.sort_values(['match_date', 'match_id', 'team_id', 'playerId'], ascending=True).reset_index(drop=True)\n",
    "\n",
    "with open('squads.pickle', 'rb') as fila:\n",
    "    all_squads = pickle.load(fila)\n",
    "\n",
    "list_of_all_vectors = []\n",
    "\n",
    "for i, match in calendar.iterrows():\n",
    "\n",
    "    vectors = get_match_vectors(match,\n",
    "                    all_performances=team_data,\n",
    "                    all_squads=all_squads,\n",
    "                    all_player_data=player_data,\n",
    "                    training=True)\n",
    "                    \n",
    "\n",
    "    list_of_all_vectors.extend(vectors)\n",
    "\n",
    "feature_list = pd.DataFrame(list_of_all_vectors)\n",
    "feature_list.to_csv('./vcheatfeatures.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b417e9b3",
   "metadata": {},
   "source": [
    "# modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83577423",
   "metadata": {},
   "outputs": [],
   "source": [
    "version = 'cheat'\n",
    "\n",
    "features = pd.read_csv(f'v{version}features.csv', index_col=0)\n",
    "features = features.dropna()\n",
    "features = features.sort_values('match_date', ascending=True)\n",
    "\n",
    "if version != 2:\n",
    "    features = features.drop(index=features[features['player_position'] == 'Substitute'].index)\n",
    "    position_dummies = pd.get_dummies(features.player_position).astype(int)\n",
    "    features = features.merge(position_dummies, left_index=True, right_index=True, how='left')\n",
    "\n",
    "weeks = features.match_week.unique()\n",
    "test_split = int(len(weeks) * 0.8)\n",
    "\n",
    "train_weeks = weeks[:test_split]\n",
    "test_weeks = weeks[test_split:]\n",
    "\n",
    "train = features[features['match_week'].isin(train_weeks)]\n",
    "test = features[features['match_week'].isin(test_weeks)]\n",
    "\n",
    "config_cols = ['player_name', 'player_position', 'team_id', 'match_id', 'match_date', 'match_week', 'player_id', 'p_std_passes']\n",
    "feats = train.drop(columns=config_cols + ['target']).columns\n",
    "target = ['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd5203d",
   "metadata": {},
   "source": [
    "## alexboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9ad425",
   "metadata": {},
   "outputs": [],
   "source": [
    "from alexboost import NegBinomial\n",
    "from alexboost import Normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd54fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "alx_norm = Normal(\n",
    "        num_trees=50, \n",
    "        num_samples_per_bucket=30,\n",
    "    )\n",
    "\n",
    "alx_neg_bin = NegBinomial(\n",
    "        num_trees=50, \n",
    "        num_samples_per_bucket=30,\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "# add a small amount to target to avoid error\n",
    "\n",
    "alx_norm.fit(train[feats], train[target].target)\n",
    "alx_neg_bin.fit(train[feats], train[target].target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28409fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_preds = alx_norm.predict(test[feats])\n",
    "neg_bin_preds = alx_neg_bin.predict(test[feats])\n",
    "\n",
    "test[['norm_mean', 'norm_std']] = norm_preds\n",
    "test[['nb_mean', 'nb_r']] = neg_bin_preds\n",
    "\n",
    "test['error'] = (test.target - test.norm_mean)\n",
    "# test['avg_error'] = (test.target - test.avg_passes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70eb66da",
   "metadata": {},
   "source": [
    "# evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4abcf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm, nbinom # Import the distributions\n",
    "\n",
    "def normal_nll(y_true, mu, sigma):\n",
    "    log_prob = norm.logpdf(y_true, loc=mu, scale=sigma)\n",
    "    return -log_prob\n",
    "\n",
    "def negative_binomial_nll(y_true, mu, r):\n",
    "    p = r / (mu + r)\n",
    "    p = np.clip(p, 1e-16, 1.0 - 1e-16)\n",
    "\n",
    "    y_true = int(y_true)\n",
    "    log_prob = nbinom.logpmf(y_true, n=r, p=p)\n",
    "    return -log_prob\n",
    "\n",
    "test['norm_nll'] = test.apply(lambda x: normal_nll(x.target, x.norm_mean, x.norm_std), axis=1)\n",
    "test['nb_nll'] = test.apply(lambda x: negative_binomial_nll(x.target, x.nb_mean, x.nb_r), axis=1)\n",
    "test['avg_nll'] = test.apply(lambda x: normal_nll(x.target, x.p_avg_passes, x.p_std_passes), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb20a697",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"AlexBoost Norm Dist NLL: {test.norm_nll.mean()}\")\n",
    "print(f\"AlexBoost NegBinom Dist NLL: {test.nb_nll.mean()}\")\n",
    "print(f\"Average Passes Norm Dist NLL: {test.avg_nll.mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07016427",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_mae = np.sum((np.abs(test.target - test.norm_mean)) / test.shape[0])\n",
    "negbin_mae = np.sum((np.abs(test.target - test.nb_mean)) / test.shape[0])\n",
    "avg_mae = np.sum((np.abs(test.target - test.p_avg_passes)) / test.shape[0])\n",
    "\n",
    "norm_rmse = np.sqrt(np.sum(np.abs(test.target - test.norm_mean)**2 / test.shape[0]))\n",
    "negbin_rmse = np.sqrt(np.sum(np.abs(test.target - test.nb_mean)**2 / test.shape[0]))\n",
    "avg_rmse = np.sqrt(np.sum(np.abs(test.target - test.p_avg_passes)**2 / test.shape[0]))\n",
    "\n",
    "print(f\"Norm MAE: {norm_mae} | Norm RMSE: {norm_rmse}\")\n",
    "print(f\"NegBin MAE: {negbin_mae} | NegBin RMSE: {negbin_rmse}\")\n",
    "print(f\"Average Passes MAE: {avg_mae} | Average Passes RMSE: {avg_rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe881f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "alx_norm.regressor.feature_importances_\n",
    "pd.DataFrame({\"feature\": train[feats].columns, \"importance\": alx_norm.regressor.feature_importances_}).sort_values(by=\"importance\", ascending=False).round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3726dec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "alx_neg_bin.regressor.feature_importances_\n",
    "pd.DataFrame({\"feature\": train[feats].columns, \"importance\": alx_neg_bin.regressor.feature_importances_}).sort_values(by=\"importance\", ascending=False).round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5dad7a",
   "metadata": {},
   "source": [
    "## misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cabf92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.groupby('player_position')['mae_error'].sum().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b540ec2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.groupby('player_position')['mae_error'].apply(lambda x: (sum(x)) / len(x)).sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6778e1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.groupby('team_id')['error'].apply(lambda x: (sum(x)) / len(x)).sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425a38f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns # Often imported as sns\n",
    "\n",
    "# test.exp_std.plot()\n",
    "sns.scatterplot(\n",
    "    data=test[test['error'] < 60].iloc[:1000],\n",
    "    x='error',\n",
    "    y='avg_minsPlayed',\n",
    "    hue='player_position'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f72095a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "train[target].target.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6250e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.sort_values('target', ascending=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
